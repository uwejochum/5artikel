---
layout:	post
title: Urheber ohne Recht
subtitle: Wie Staat und Bürokratie mittels Open Access Wissenschaftler enteignen
author:	Uwe Jochum
tags:   [Digitalisierung,»Open Access«,Wissenschaftsfreiheit]
---

<img src="https://vg04.met.vgwort.de/na/581a4cc5989d4782ab543698c34ff5a5" width="1" height="1" alt="">

*Der nachfolgende Beitrag erschien ursprünglich im Jahre 2009 in der
Zeitschrift* Lettre International, *Nummer 87, S.&nbsp;7--12. Daß
ich ihn nach so langer Zeit hier erneut veröffentliche, liegt nicht
nur an einem gewissen Interesse an Dokumentation, sondern vor allem
an den jüngsten Entwicklungen im deutschen Bibliothekswesen. Dort
wird munter zensiert und die Zensur als »Kampf gegen rechts«
legitimiert; und dort greift man nun auch ganz sichtbar zu
organisatorischen Maßnahmen, die jeden als »rechts« freindmarkierten
Akteur ins Aus befördern.*

*Das geschieht im Augenblick mit der Bibliothek des Konservatismus,
die jahrelang eine teilnehmende Bibliothek am »Gemeinsamen
Bibliotheksverbund« (GBV) war, der nun aber nicht nur begründungslos
gekündigt wurde, sondern deren [Katalogdaten nun auch aus dem GBV
entfernt](https://jungefreiheit.de/kultur/2026/das-grosse-loeschen-hat-begonnen/)
wurden. Der Leser muß dazu wissen: Eine anlaß- und begründungslose
Kündigung einer an einem Bibliotheksverbund partizipierenden
Bibliothek ist meines Wissens in der Geschichte der
Bibliotheksverbünde ein absolutes Novum — und kein gutes
Zeichen. Denn hier wird die Zensur von der Direktzensur von Büchern
auf die Organisationsebene verlagert und durch eine vermeintlich
legale Aktion einer staatlichen Behörde, zu denen der GBV zählt, ein
politisch unliebsamer Akteur einfach lahmgelegt. Das ist das
bibliothekarische Äquivalent zu Nancy Faesers innenministeriellem
Versuch, die Zeitschrift* Compact *dadurch zu unterdrücken, daß man
nicht die Zeitschrift verbot, sondern dem Verlag die Weiterarbeit
unmöglich machte.*

*Faeser hat vor Gericht verloren, aber ihr Vorbild scheint weit ins
Bibliothekswesen hinein zu leuchten und nun im GBV einen gehorsamen
Nachfolger gefunden zu haben. Es kommt freilich hier im Falle des
GBV genauso wenig wie im Falle Faesers darauf an, daß die staatliche
Seite vor Gericht gewinnt — worauf es bei Aktionen diesen Typs nur
noch ankommt, ist, dem politischen Gegner ein Maximum an Schaden
zuzufügen und die juristischen Verfahren in die Länge zu ziehen, um
durchs Ziehen der Verfahren den Schaden beim Andersmeiner noch
weiter zu erhöhen. Wenn der GBV also nach Monaten (oder gar Jahren)
juristisch verloren haben wird, wird man auf seiten des Staates
einfach mit den Schultern zucken und die Kosten des Verfahrens dem
Steuerzahler aufbrummen — alles wird falsch und illegal gewesen
sein, aber die Staats- und Behördenverantwortlichen werden sich ins
Fäustchen lachen und befördert werden.*

*Das ist die Lage, und sie hat eine Vorgeschichte. Diese besteht in
der allmählichen Aushöhlung des Staates und seiner Funktionen
dadurch, daß die Parteien sich auf allen Ebenen breitgemacht und die
Staatsfunktionen zu Parteifunktionen umgebogen haben. Das Ende
dieser Entwicklung meldete sich schon vor langem, und nun wird es
täglich sichtbarer: Die staatlichen Institutionen arbeiten nicht als
neutrale Organisationen zugunsten der Staatsbürger, sondern sind
Akteure im politischen Kampf, der immer stärker eskaliert, je
stärker die staatlichen Behörden ent-neutralisiert werden, so daß
die politische Auseinandersetzung zu ihrer Rohform zurückfindet, dem
»entweder Ich oder Du«.*

*Zu dieser Aushöhlungsgeschichte gehört, daß der Staat sich Zug um
Zug die Wissenschaften hörig gemacht hat. Nicht durch auf der Bühne
direkt sichtbare Gewaltsamkeiten, sondern hintenherum, durch
allmähliche Verschiebung der Rahmenbedingungen für Wissenschaft. Die
zentrale Verschiebung, die hier zu verbuchen ist und um die es im
nachfolgenden Artikel geht, ist die Änderung des wissenschaftlichen
Publikationssystems von einem System, in dem neben den
Wissenschaftlern unabhängige Verlage und steuerfinanzierte
Bibliotheken ein Kooperationssystem bildeten, zu einem System, in
dem die Wissenschaftler und Verlage in ein unmittelbar
staatsfinanziertes und staatsgelenktes Veröffentlichungssystem
gezwungen werden, das digital operiert. Am Ende der Entwicklung
steht eine Wissenschaft, die staatliche Auftragsforschung betreibt
und Wissenschaftskarrieren über die Anpassungsfähigkeit der
Wissenschaftler an die staatlichen Wünsche steuert.*

*Die Bibliothek des Konservatismus steht als eine privat finanzierte
und verwaltete Wissenschaftsbibliothek dieser Entwicklung diametral
entgegen. Sie ist der ärgerliche Stein, über den die
digitalisierenden Bibliotheks- und Wissenschaftsverwalter gerade
stolpern. Und es wird sein, wie es immer war: Gerade dieser Stein,
über den alle stolpern, wird sich als Eckstein für ein neues und
stabiles Gebäude erweisen.*

---

# Urheber ohne Recht

## Aliis inserviendo consumor

Im Jahr 2007 haben in Deutschland 121 Millionen Menschen öffentliche
Bibliotheken besucht, und neben drei Millionen Studenten haben fast
800&nbsp;000 Bürger aus wissenschaftlichen Bibliotheken Bücher
entliehen. Im selben Jahr zählte man 102 Millionen Museums- und 31
Millionen Theaterbesucher. Das alles ist erfreulich. Aber die Freude
darüber, daß die Kultureinrichtungen, die der Steuerzahler mit viel
Geld unterhält, von ebendiesem Steuerzahler auch genutzt werden,
wird durch die kleine Entdeckung getrübt, daß Besuchsintensität und
Steuertransfer sich umgekehrt proportional zueinander verhalten. So
gibt der Steuerzahler in jedem Jahr für seine Theater inklusive der
Musiktheater und der Orchester knapp 3 Milliarden Euro aus, für die
Museen jedoch nur etwa die Hälfte (1,54 Milliarden Euro) und für die
öffentlichen Bibliotheken gar nur 1,1 Milliarden Euro. Selbst wenn
man zu den öffentlichen noch die wissenschaftlichen Bibliotheken
dazunimmt und dann auf ein Gesamtfinanzierungsvolumen aller
Bibliotheken von 1,6 Milliarden Euro kommt, muß man feststellen:
Theater und Musik sind dem Steuerzahler doppelt soviel wert wie
Museen und Bibliotheken, auch wenn er sie dreimal weniger als die
Museen und viermal weniger als die Bibliotheken besucht.

Diese Asymmetrie zwischen Benutzung und Steuertransfer hängt
sicherlich damit zusammen, daß Theater und Museen mit der sich seit
Jahrzehnten verstärkenden Event-Kultur enger verbunden sind als die
Bibliotheken. Während man daher ins Theater oder Museum geht, um
dort zu verweilen und etwas zu erleben und sich diesen ab und an
gegönnten kulturellen Erlebnisspaß auch gerne etwas kosten läßt,
betritt man die Bibliotheken nur, um sie möglichst rasch wieder mit
einem Stapel kostenlos entliehener Bücher zu verlassen. Diese
Unvereinbarkeit von Bibliotheken und Event-Kultur hat im
wesentlichen zwei Gründe.

Da ist zunächst das institutionelle Selbstverständnis der
Bibliotheken, das dem Primat des unauffälligen Funktionierens
gehorcht. Das macht die Bibliotheken im Alltag --- wie alles, was
reibungslos funktioniert --- unsichtbar und läßt sie nur im
Augenblick einer auftretenden Störung für diesen Augenblick sichtbar
werden. Die Größe der Störung gibt dabei den Aufmerksamkeitsindex
an, der vom kleinen privaten Ärger (etwa wegen des Ausfalls der
Verbuchungscomputer bei der Buchausleihe) bis zur öffentlichen
Katastrophenstimmung reichen kann (wie es in Weimar im Jahre 2004
beim Brand der Anna Amalia Bibliothek geschah). Aber wie groß dieser
Aufmerksamkeitsindex auch immer sein mag, er verflüchtigt sich schon
nach kurzer Zeit wieder; und an die Stelle öffentlicher Aufregung
tritt der Normalzustand aufmerksamkeitstechnischer Unsichtbarkeit,
in dem die Bibliotheken in einem grauen Schleier verschwinden.

<img
src="https://upload.wikimedia.org/wikipedia/commons/d/dd/Brand_Anna_Amalia_22.30Uhr.JPG"
alt="Drawing" style="width: 650px;"/>[Brand der Herzogin Anna Amalia
Bibliothek. Quelle: Enrico Herzel, CC BY-SA 3.0, via Wikimedia
Commons.]

Dieser Betriebsmodus des unauffälligen Funktionierens hängt nun aber
mit dem zweiten Grund, der Bibliotheken mit der Event-Kultur
inkompatibel macht, unmittelbar zusammen. Dieser zweite Grund liegt
darin, daß Bibliotheken sich selbst seit dem 19. Jahrhundert
zunehmend nicht mehr als Institutionen verstehen, in denen man einen
Zugang zu aufregender Kultur in Buchform findet (was auch immer das
Aufregende daran sein mag), sondern als Vermittlungseinrichtungen
von »Informationen«. Hier kommt es nicht darauf an, sich durch die
Unschärfen eines Informationsbegriffs zu plagen, der bunt zwischen
dem Pol eines Fachterminus der Nachrichtentechnik und dem Pol eines
Allerweltssynonyms für so etwas wie »Wissen« schillert. Worauf es
ankommt, ist schlicht dies: daß mit dem Begriff der »Information«
eine nicht-materielle Bedeutung oder ein nicht-materieller Inhalt
gesetzt ist, der auf einem beliebigen Trägermedium zirkulieren
kann. Damit suspendiert der Informationsbegriff die Dialektik von
Form und Inhalt und die sich daran anschließenden Debatten, die nach
der kritischen Zusammengehörigkeit beider fragen, um auf den Inhalt
als dem Eigentlichen zu fokussieren und die Form als etwas
Beliebiges und zu Vernachlässigendes zu betrachten.

Daraus resultiert unmittelbar die Vorliebe der Bibliothekare für
eine solche Form, die in maximalem Verschwinden einen maximalen
Inhalt freizusetzen in der Lage ist oder dies zumindest
verspricht. Und genau dieses Versprechen tragen die digitalen Medien
vor sich her: Fluktuierende Datenformate, die nach wenigen Jahren
durch neue Formate ersetzt werden, völlig ungewisse
Langfristarchivierbarkeit der Daten, rapide Erosion der physischen
Datenträger sind Elemente einer medienmateriellen Instabilität, die
man als systemisch gewordene Leugnung alles Materiellen und der mit
dem Materiellen gesetzten Grenzen begreifen muß; einer Leugnung, die
die Basis darstellt, auf der die digitalen Medien ihre schier ins
Endlose wachsende Speicherkapazität und ebenso ihre schier endlose
Transmissionsbeschleunigung realisieren. Für diese mediale Form, in
der Immaterialität, Grenzenlosigkeit und Beschleunigung
zusammenschießen, scheint es nur einen angemessenen Inhalt geben zu
können: das »Weltwissen«. Das soll ein Wissen sein, das aus seiner
regionalen Gefangenschaft --- sei es im Kopf einzelner Individuen,
sei es in lokalen Institutionen, sei es in regionalen Gemeinschaften
oder kontinentalen Netzwerken --- befreit und in die Freiheit des
Internets entlassen wurde, wo es zu jeder Zeit an jedem Ort im Nu
zur Verfügung steht.

Mit anderen Worten: Die Bibliotheken, die sich selbst im Modus des
unauffälligen Funktionierens institutionell zum Verschwinden
bringen, finden im digitalen Netz das Medium, das dieses funktionale
Verschwinden als Maximum von Funktion realisiert. Man muß das in den
Bibliotheken nur noch möglichst vollständig umsetzen und hat dann
vor sich, was Bibliotheken heutzutage sind: ein allmählich verlegen
wirkender materieller Appendix des Internet, der darauf setzt, die
letzten Spuren seiner Materialität zu tilgen, um endlich und bald
ein funktional-immaterieller Informationsknoten im Internet sein zu
können.  Wenn man daher von modernen und gar postmodernen
Bibliotheken spricht, dann muß man sich bewußt machen, daß diese
längst von Biblio- zu Media-theken umgebaut wurden und nun dabei
sind, auch noch das *theke* (griechisch für »Behältnis«,
»Repositorium«) aufzugeben. An seine Stelle tritt der völlig neue
Metaphernraum des »Netzes«, der in der Abkehr von konkreten Orten
und konkreten Materialitäten eine dialektische Volte verspricht: Was
nirgendwo ist, soll hinfort überall sein, eine Totalpräsenz des
absoluten Wissens, das ohne umständliche Reflexion zum Download
bereitgestellt wird.

<img
src="https://upload.wikimedia.org/wikipedia/commons/3/34/Weimar%2C_Herzogin_Anna_Amalia_Bibliothek%2C_2019-09_CN-02.jpg"
alt="Drawing" style="width: 450px;"/>[Der Rokokosaal in der Herzogin
Anna Amalia Bibliothek. Quelle: Steffen Schmitz (Carschten), CC
BY-SA 4.0, CC BY-SA 4.0, via Wikimedia Commons.]

Die Sache wird deutlicher, wenn wir einen Blick auf den Anfang der
habituell-institutionellen und medialen Transformation der
Bibliotheken und Bibliothekare werfen. An diesem Anfang finden wir
den Dresdener Bibliothekar Friedrich Adolf Ebert (1791--1834), der
in seiner kleinen und in Bibliothekskreisen vielzitierten Schrift
über *Die Bildung des Bibliothekars* (1820) das Anforderungsprofil
entwickelte, das von einem vorbildlichen Bibliothekar erfüllt werden
müsse. Im Rahmen dieser Profilbeschreibung wurden nicht nur, dem
Geschmack der Zeit entsprechend, vom Bibliothekar enzyklopädische
Kenntnisse verlangt, Ebert modellierte vielmehr darüber hinaus das
individuelle bibliothekarische Lokalgedächtnis zu einem
Katalogersatz, um über jedes Buch in der Bibliothek Auskunft geben
und seinen Standort in den Regalen bezeichnen zu können. Der Preis
für diesen Versuch, die Bibliothek vollständig im Kopf des
Bibliothekars abzubilden, war freilich hoch: Um sich der Abbildungs-
und Orientierungsarbeit in enzyklopädischem Maßstab widmen zu
können, sollte der Bibliothekar auf eigene schriftstellerische
Tätigkeit völlig verzichten und also darin zu einem Kulturfaktor
werden, daß er sich als eigenständiger Kulturproduzent durchstrich.

Das war damals neu, und es war ungeheuer. Denn seitdem es
wissenschaftliche Bibliotheken gab, hatten dort Wissenschaftler
zugleich als Bibliothekare und Bibliothekare zugleich als
Wissenschaftler gearbeitet und der textuellen Überlieferung des
Abendlandes die Gestalt gegeben, die sie heute hat. Begonnen hatte
das im Museion in Alexandria, das von den Ptolemäern um 300
v. Chr. als Forschungseinrichtung samt Großbibliothek gegründet
worden war; das Mittelalter setzte diese Geschichte der
Zusammengehörigkeit von intellektueller und Bibliotheksarbeit
bruchlos fort; und die Neuzeit schloß dabei ebenso bruchlos an das
Mittelalter an: Leibniz wurde in Hannover Bibliothekar der Welfen,
um sich seinen zahlreichen wissenschaftlichen Projekten und einer
Geschichte des Fürstenhauses widmen zu können; Lessing wurde in
Wolfenbüttel Bibliothekar, um als intellektuelles Aushängeschild
seines Landesfürsten zu dienen; Kant arbeitete sechs Jahre lang als
Bibliothekar an der Universitätsbibliothek in Königsberg; und
Christian Vulpius, Goethes Schwager und Autor des weltberühmten
Räuberromans *Rinaldo Rinaldini*, ließ sich trotz dieser Berühmtheit
von Goethe in Weimar als Bibliothekar unterbringen. Kurz und gut:
Ebert griff keine singuläre Fehlentwicklung im Bibliothekswesen
seiner Zeit an, indem er gegen schriftstellernde und
wissenschaftlich arbeitende Bibliothekare Front machte; sein Angriff
richtete sich vielmehr gegen das tradierte Bibliotheksmodell, in dem
sich bibliothekarische Arbeit und eigene schriftstellerische und
wissenschaftliche Ambitionen seit Jahrtausenden vertragen hatten.

<img
src="https://upload.wikimedia.org/wikipedia/commons/9/9e/Friedrich_Adolf_Ebert%2C_Lichtdruck.png"
alt="Drawing" style="width: 450px;"/>[Friedrich Adolf Ebert. Quelle:
Wolf aus Dessau, vermutlich identisch mit »Communalwolf«,
Historienmaler und Porträtzeichner, Public domain, via Wikimedia
Commons.]

Daß Ebert mit diesem Angriff erfolgreich war, hatte einen einfachen
Grund. Als nämlich ab 1803 im Zuge der Säkularisierung der Klöster
die Klosterbibliotheken aufgelöst wurden, war man mit dem Problem
konfrontiert, was mit den von den Klöstern über Jahrhunderte hin
gesammelten enormen Büchermassen zu geschehen habe. Auch wenn man
das Problem *grosso modo* dadurch löste, daß man mindestens die
Hälfte der in den Klöstern vorhandenen Bücher wegwarf, war das, was
übrigblieb und nun auf Hof- und Universitätsbibliotheken umverteilt
wurde, immer noch eine solche Menge, daß an diesen Bibliotheken das
gewohnte bibliothekarische Geschäft ins Stocken geriet. In dieser
Situation schien es nur noch eine Lösung zu geben, und die lag
darin, daß die Bibliothekare sich stärker als jemals zuvor in der
Geschichte der Bibliotheken mit den Techniken der Lagerhaltung von
Büchern und der angemessenen Katalogisierung gedächtnissprengender
Büchermassen auseinandersetzten und also die eigene literarische
Produktion hintanstellten, um das zu werden, was ein Text der Zeit
»literärische Geschäftsmänner« nennt.

Ebert bot in dieser Situation den Bibliothekaren eine neue
Berufsidentität an, die den Verzicht auf eigene
literarisch-wissenschaftliche Produktion dadurch zu kompensieren
versprach, daß die bibliothekarischen Geschäftsmänner als
einhundertprozentige Bibliothekare mit einer eigenen Laufbahn
belohnt wurden. Man mußte dabei lediglich, anders als Ebert es
gewollt hatte, das individuelle Lokalgedächtnis des Bibliothekars
durch den Katalog als wichtigstes Auskunftsmittel ersetzen und
konnte auf dieser Basis dann die Laufbahn von Berufsbibliothekaren
konstruieren: Für sie trat an die Stelle des
wissenschaftlich-literarischen Schreibens das Schreiben von
Katalogen, wobei man die entsagungsvolle Produktion von
Katalogzetteln hinfort als »Dienst« am Bibliotheksbenutzer
betrachtete. Das alles ließ sich als Ebertscher Wahlspruch den
nachfolgenden Bibliothekarsgenerationen mit auf den Weg geben ---
*aliis inserviendo consumor* (»im Dienst an anderen verbrauche ich
mich«) --- und bildet seither den mentalen Habitus der
Bibliothekare. Nur daß man anstelle des unverständlich gewordenen
Latein heute von »Dienstleistung« und besser noch »Service« spricht.

Man kann den revolutionären Schnitt, den Ebert für die
Bibliotheksgeschichte bedeutet, kaum überschätzen. Er brachte für
die Bibliothekare eine vollständige Annullierung des eigenen
produktiven Bezugs auf konkrete Inhalte, die in konkreten Objekten
--- *vulgo* Büchern --- verkörpert sind, um an die Stelle solcher
Inhalte die Arbeit am Katalog als Vermittlungsinstrument zu
setzen. Man muß dann nur noch die über den Katalog vermittelten
Inhalte vom Buch als Medium ablösen, um dort zu sein, wo wir
bibliothekarisch heute stehen: Es ist der Punkt, an dem die
Bibliotheken als Informationsknoten ins Internet überzugehen
beginnen, wo sie materielosen und damit buchfreien reinen Geist in
Form von Informationshäppchen umschlagen, die man über
Web-2.0-Spielereien an Mann und Frau zu bringen sucht. Um das tun zu
können, muß man freilich dafür sorgen, daß alles, was die Menschheit
bislang in der medialen Form des Buches mitteilen und überliefern
wollte, nun den Weg aus dem Buch ins Internet findet und folglich in
digitaler Form zur Verfügung gestellt werden kann.

<img
src="https://upload.wikimedia.org/wikipedia/commons/e/e2/Google_Campus%2C_Mountain_View%2C_CA.jpg"
alt="Drawing" style="width: 650px;"/>[Google Campus. Quelle: Austin
McKinley, CC BY 3.0, via Wikimedia Commons.]


## Don't be evil

Die digitale Transformation der Bücher und Bibliotheken ist zunächst
eine Frage der Technik und damit zwangsläufig auch eine Frage des
Geldes. Denn obwohl man immer wieder lesen kann, daß die
Digitaltechnik immer billiger werde, ist das weniger als die halbe
Wahrheit. Die ganze Wahrheit liegt darin, daß die immer billigere
Hardware und die immer billigere oder gar kostenlose Software in
eine Innovationsspirale eingefügt sind, die aufgrund der planetaren
Vernetzung der Computersysteme dafür sorgt, daß jede Innovation an
einem Punkt des Globus und in einem Segment der Hard- oder Software
durchs ganze System durchgereicht wird und also ein technisch
hochgradig instabiles Gesamtsystem erzeugt, in dem man die einzelnen
Elemente permanent austauschen muß. Das führt dazu, daß bei
abnehmenden Kosten der Systemkomponenten die Kosten für das
Gesamtsystem in die Höhe schießen.  Wobei man nicht vergessen darf,
daß das größte Problem der Digitalisierung, nämlich die
Langfristarchivierung der Daten, noch völlig ungelöst und in seinen
Kostendimensionen daher noch gar nicht zu greifen ist.

Auf welchen finanziellen Höhen man sich mit alldem bewegt, läßt sich
nur erahnen, denn niemand hat sich bislang die Mühe gemacht, die
bereits aufgelaufenen Gesamtkosten der Digitalisierung auf
nationalem oder gar globalem Niveau zu errechnen und die zukünftigen
Kosten zu antizipieren.  Aber man kann ein Gefühl für die Sache
bekommen, wenn man sich vor Augen führt, daß Google für die
Indexierung von etwa acht Milliarden Internetsites, die freilich nur
einen Teil des Internet darstellen, rund 250 000 Linux-Server
betreibt, die alle drei Jahre ausgetauscht werden müssen, was für
Google Kosten von 263 Mio. Dollar im Jahr bedeutet. Der gesamte
Netzbetrieb Googles ist freilich erheblich teurer und schlägt
jährlich mit rund 9,4 Mrd. Dollar zu Buche. Und selbst dieser Betrag
ist weniger als die Hälfte der Kosten, mit denen Google jedes Jahr
zurechtkommen muß, nämlich rund 23,6 Mrd. Dollar. Mit diesen
immensen Beträgen finanziert Google die Infrastruktur, die die von
Dritten bereitgestellten digitalen Inhalte abgreift und zugänglich
macht. Diese Inhalte werden u. a. von Zeitungen, Presseagenturen,
Verlagen und Bibliotheken bereitgestellt und sind derzeit im Netz
zumeist noch kostenlos zu haben, weil die kommerziellen Anbieter
hoffen, daß das Netz als Werbeplattform für die zu bezahlenden
gedruckten Publikationen tauge und der Absatz von Gedrucktem die
Netzkosten amortisiere, und weil die staatlichen Anbieter die Kosten
für die digitalen Inhalte hinter dem Rücken der Steuerzahler über
Subventionsprogramme abdecken, die ein ums andere Mal ein Mehr an
»Innovation« verheißen.

Nun ist das Verhalten der privaten und der staatlichen
Digitalisierungsakteure nur möglich, solange der Rubel rollt und man
die Hoffnung haben kann, daß die Kosten der Digitalisierung schon
noch hereinkommen, irgendwann. Aber der Rubel rollt nicht mehr. Die
ökonomische Krise hat das bunte Zukunftsprospekt gegen ein graues
Gegenwartspapier getauscht, und auf diesem Papier kann man
nachlesen, daß die Zeit der kostenlosen digitalen Netzinhalte zu
Ende geht. So hat inzwischen der Medienmogul Rupert Murdoch Googles
Geschäftsmodell, das auf einer unbezahlten Verwertung fremder
Inhalte beruht, öffentlich als »Diebstahl« gebrandmarkt und Schritte
angekündigt, die Murdoch-Blätter für Google zu sperren, um in
Zukunft die Inhalte ohne den Umweg über Google im Netz selbst zu
verkaufen; und in Deutschland denken die privaten Fernsehsender
darüber nach, für ihre bislang werbefinanzierten Programme
zusätzlich Gebühren zu erheben. Nur die steuerfinanzierten
staatlichen Digitalisierungsakteure tun so, als ginge sie die Krise
nichts an, und träumen ihren Traum vom digitalen Umsonst ungerührt
weiter.

Lassen wir ihnen diese Lizenz zum Träumen und beschäftigen uns
einstweilen mit dem dritten Faktor, der zusammen mit der Technik und
dem Geld über die Zukunft der Digitalisierung des »Weltwissens«
entscheidet: dem Recht. Denn wer Texte ins Internet stellen will,
der kann das nur mit der Zustimmung der Autoren tun. Das gilt
natürlich auch für die wissenschaftlichen Autoren als denjenigen,
die durch ihre Arbeit das »Weltwissen« hervorbringen und also den
qualitativen Nukleus darstellen, ohne den keine Bibliothek und keine
Suchmaschine der Welt »wissenschaftliche Informationen« zu bieten
hätte.

Geht man dem juristischen Problem des Einverständnisses zur
Digitalisierung nach, muß man zwei Dinge auseinanderhalten. Da sind
auf der einen Seite die vielen Texte, die »gemeinfrei« sind. Das
sind Texte, deren Autoren seit mehr als siebzig Jahren tot sind,
weshalb diese Texte keinem Urheberrecht mehr unterliegen und von
jedermann nachgedruckt oder digitalisiert werden können, ohne daß
dieser Jedermann vorher jemanden fragen oder Lizenzgebühren
entrichten müßte. Ob man diese Texte digitalisiert, ist folglich
keine juristische Frage, sondern eine pragmatische und eine
finanziell-technische. Auf der anderen Seite aber finden sich all
die Texte, deren Autoren noch leben oder weniger als siebzig Jahre
tot sind, so daß es einen oder mehrere Rechteinhaber gibt, die
darüber bestimmen können, was mit diesen Texten geschehen darf und
was nicht. Und damit reduziert sich das Problem des
Einverständnisses zur Digitalisierung auf einen im Grunde einfachen
Sachverhalt: Wer wissenschaftliche Texte von lebenden Autoren oder
solchen, die noch keine siebzig Jahre tot sind, ins Netz stellen
will, muß vorher fragen, ob er es tun darf, und wenn er es tun darf,
muß er dafür u. U.  Lizenzgebühren entrichten; fragt er nicht und
digitalisiert er trotzdem, begeht er einen Rechtsbruch.

<img
src="https://upload.wikimedia.org/wikipedia/commons/a/ad/Participants_at_Budapest_meeting%2C_December_1%2C_2001.jpeg"
alt="Drawing" style="width: 600px;"/>[Die Teilnehmer der Budapester
Open-Access-Initiative. Quelle: Lesliekwchan, CC BY-SA 4.0, via
Wikimedia Commons.]

Nun ist ein solches Fragen angesichts der Unzahl von Autoren und
Texten natürlich eine mühsame Sache, und man kann sich vorstellen,
daß es viel Zeit und Geld kostet, all die notwendigen Erkundigungen
einzuholen und sich über Zahlungsmodalitäten mit Autoren und
Urhebererben zu einigen.  In dieser Situation kann man durchaus auf
den Gedanken kommen, sich das Fragen zu sparen und fraglos zu
digitalisieren, was das Zeug hält. Ist man dabei schnell genug und
schafft man dabei so massiv Fakten, daß der Faktenberg auf das
geltende Recht drückt, kann man darauf spekulieren, daß
Öffentlichkeit und Politik dank dieses Drucks lahm werden und den
Rechtsbruch durchwinken, zumal mit Ausnahme der Autoren alle anderen
von diesem Rechtsbruch zu profitieren scheinen: Sie finden plötzlich
im Netz schnell und kostenlos Texte, zu deren Lektüre sie früher die
Dienste einer Buchhandlung oder Bibliothek hätten in Anspruch nehmen
müssen. Das ist der Trick, den Google praktiziert, seit [»Google
Books«](https://books.google.de/) ans Netz ging und in großem Stil
Bücher aus Bibliotheken zu digitalisieren begann, ohne sich darum zu
kümmern, ob diese Bücher »gemeinfrei« sind oder noch dem
Urheberrecht unterliegen. Es ist die Politik einer Firma, die sich
den Wahlspruch »Don’t be evil« auf die Fahnen geschrieben hat und
nun mit aller Macht dabei ist, sich durch eine bösartige
Übertölpelung der nationalen Urheberrechte einen so massiven Vorteil
zu verschaffen, daß sie schließlich als absoluter Souverän des
Digitalen jenseits von Ökonomie, Politik und Recht agieren kann:
Kein möglicher Konkurrent, kein Staat und auch kein Rechtssystem
soll die digitale Dominanz Googles noch gefährden können.

Der neben Google wichtigste Akteur auf dem Feld der Digitalisierung
ist der Staat, der sich seit einiger Zeit dem Ziel der
Digitalisierung von Wissenschaft verschrieben hat. Damit hat er sich
freilich von vorneherein in ein doppeltes Konkurrenzverhältnis zu
Google gesetzt: Er muß, will er mit Google mithalten, derselben
Logik des raschen Digitalisierens großer Textmengen folgen, und er
muß, anders als Google, diese Digitalisierung auf rechtskonforme
Weise betreiben. Denn als Staat ist er auf das Grundrecht der
Wissenschaftsfreiheit verpflichtet und muß es folglich ganz dem
Wissenschaftler überlassen, ob und wann und wie und wo dieser einen
Artikel oder ein Buch veröffentlichen will. Nun braucht man nicht
lange nachzudenken, um zu sehen, daß das Ziel der raschen und das
Ziel der rechtskonformen Digitalisierung in einem
Spannungsverhältnis zueinander stehen: Wer sich an das Recht hält
und die Wissenschaftler fragt, ob sie digital publizieren wollen,
muß ihr mögliches Nein akzeptieren und wird daher aufgrund dieses
rechtskonformen Verfahrens niemals jenes Digitalisierungstempo
vorlegen können, mit dem Google die Öffentlichkeit so sehr zu
beeindrucken sucht.  Für den Staat heißt das, daß er entweder die
Rolle des großen Innovators und Konkurrenten von Google ablegen ---
oder einen Weg finden muß, um sein eigenes Recht umgehen und das
Digitalisierungstempo anziehen zu können.

Das Spannungsverhältnis löst sich auf, wenn man als Staat die
Notwendigkeit des Fragens und damit das mögliche Nein der Autoren
erst gar nicht zum Thema macht, sondern die Digitalisierung von
Wissenschaft über den Aufbau einer staatlich geförderten
Publikationsinfrastruktur betreibt, die dem Wissenschaftler faktisch
keine Wahl mehr läßt. Dann kann man als Staat den Google-Trick des
Nicht-Fragens, aber Machens kopieren, ohne sich dem Vorwurf des
direkten Rechtsbruchs aussetzen zu müssen. Man kann dann sonntags
die Wissenschaftsfreiheit predigen, um sie den Rest der Woche bequem
zu ignorieren. Die Kopie dieses Google-Tricks ist das, was als »Open
Access« zu beobachten ist: die großangelegte Digitalisierung
wissenschaftlicher Veröffentlichungen unter Umgehung des
Urheberrechts und der Wissenschaftsfreiheit, zum angeblichen Besten
der Menschheit. Das müssen wir uns näher anschauen.

Öffentlich sichtbar wurde »Open Access« mit der im Jahre 2002
publizierten [»Budapester
Erklärung«](https://de.wikipedia.org/wiki/Budapest_Open_Access_Initiative). Darin
heißt es: »*Open access* meint, dass diese Literatur \[gemeint war
die wissenschaftliche Zeitschriftenliteratur, U.J.\] kostenfrei und
öffentlich im Internet zugänglich sein sollte, so dass Interessierte
die Volltexte lesen, herunterladen, kopieren, verteilen, drucken, in
ihnen suchen, auf sie verweisen und sie auch sonst auf jede denkbare
legale Weise benutzen können, ohne finanzielle, gesetzliche oder
technische Barrieren jenseits von denen, die mit dem Internet-Zugang
selbst verbunden sind. In allen Fragen des Wiederabdrucks und der
Verteilung und in allen Fragen des Copyright überhaupt sollte die
einzige Einschränkung darin bestehen, den jeweiligen Autorinnen und
Autoren Kontrolle über ihre Arbeit zu belassen und deren Recht zu
sichern, dass ihre Arbeit angemessen anerkannt und zitiert wird.«

Nun mag es für einen Wissenschaftler in der Tat die größte
Befriedigung darstellen, recht häufig zitiert zu werden. Aber in der
Freude über häufige Zitationen darf man nicht übersehen, daß es
essentiell zum wissenschaftlichen Geschäft gehört, daß der
Wissenschaftler Herr über seine Publikationen bleibt, sei es, um
dieses oder jenes Versehen korrigieren, sei es, um einen Text
gegebenenfalls vollständig zurückziehen zu können. Ebendiese
Kontrolle gesteht »Open Access« den Wissenschaftlern nun aber gerade
nicht zu, denn »Open Access« hat sich zum Ziel gesetzt, auch die
juristischen Barrieren beim Umgang mit Texten zu beseitigen, indem
man den Autoren Lizenzen andient, die, wie die
»Creative-Commons«-Lizenzen, nicht widerrufbar sind, oder die, wie
die »GNU General Public Licence«, es dem Leser eines Textes
ermöglichen, diesen Text zu verändern und den veränderten Text
(unter Kenntlichmachung der veränderten Passagen) weiterzugeben. Das
mag nun zwar der juristische Triumph der Rezeptionsästhetik sein,
aber es hat mit dem wissenschaftlichen Publizieren, wie es seit der
Antike praktiziert wurde, nicht das geringste mehr zu tun. Denn an
die Stelle des von seinem Autor verantworteten letztgültigen Textes
tritt ein undurchschaubares Sammelsurium von nicht mehr oder nur
noch teilweise gültigen Vorab- und Preprint-Versionen, hinter denen
die letztgültige Textversion verschwindet; das Ganze dann potenziert
durch Textversionen, in denen bastelwütige Leser in den
ursprünglichen Text hineinmontiert haben, was sie für richtig
halten, der originale Autor aber ausgestrichen hätte.

<img
src="https://upload.wikimedia.org/wikipedia/commons/9/91/Berlin%2C_Mitte%2C_Markgrafenstra%C3%9Fe_37%2C_Wissenschaftsforum_am_Gendarmenmarkt_02.jpg"
alt="Drawing" style="width: 550px;"/>[Der Berliner Standort der
Max-Planck-Gesellschaft. Quelle: Jörg Zägel, CC BY-SA 3.0, via
Wikimedia Commons.]

Das alles ist kein Spaß, den sich einige wissenschaftsfremde
Weltverbesserer mit der Wissenschaft erlauben, vielmehr ist hier
bitterer wissenschaftlicher und politischer Ernst am Werk. Denn
spätestens, als im Herbst 2003 namhafte internationale und deutsche
Forschungsorganisationen die [»Berliner Erklärung über den offenen
Zugang zu wissenschaftlichem
Wissen«](https://de.wikipedia.org/wiki/Berliner_Erkl%C3%A4rung_%C3%BCber_offenen_Zugang_zu_wissenschaftlichem_Wissen)
unterzeichneten, wurde »Open Access« auf die Agenda der deutschen
Forschungspolitik gesetzt. Dabei nahm man keineswegs Anstoß an den
urheberrechtsfeindlichen und die Wissenschaftsfreiheit
aufkündigenden Formulierungen der »Budapester Erklärung«, sondern
erklärte öffentlich, ein wissenschaftliches Publikationswesen
aufbauen zu wollen, in dem unwiderrufliche Lizenzen und die Freiheit
zum wissenschaftlichen Text-Patchwork der Normalfall sein
sollten. Um es in den Worten der »Berliner Erklärung« zu sagen: »Die
Urheber und die Rechteinhaber solcher \[wissenschaftlichen\]
Veröffentlichungen gewähren allen Nutzern unwiderruflich das freie,
weltweite Zugangsrecht zu diesen Veröffentlichungen und erlauben
ihnen, diese Veröffentlichungen --- in jedem beliebigen digitalen
Medium und für jeden verantwortbaren Zweck --- zu kopieren, zu
nutzen, zu verbreiten, zu übertragen und öffentlich wiederzugeben
sowie Bearbeitungen davon zu erstellen und zu verbreiten, sofern die
Urheberschaft korrekt angegeben wird. (Die Wissenschaftsgemeinschaft
wird, wie schon bisher, auch in Zukunft Regeln hinsichtlich
korrekter Urheberangaben und einer verantwortbaren Nutzung von
Veröffentlichungen definieren.) Weiterhin kann von diesen Beiträgen
eine geringe Anzahl von Ausdrucken zum privaten Gebrauch angefertigt
werden.«

Die Umsetzung dieser Ziele stellte sich die »Berliner Erklärung« so
vor, daß man die mit Forschungsmitteln unterstützten Forscher »darin
bestärk\[t\], ihre Arbeiten gemäß den Grundsätzen des Open
Access-Paradigmas \[sic\] zu veröffentlichen«. Und weil man dann
doch nicht ignorieren konnte, daß man mit der ganzen Sache quer zum
geltenden Urheberrecht und der Wissenschaftsfreiheit steht,
versicherte man den Lesern ganz zum Schluß, daß man »die
Weiterentwicklung der bestehenden rechtlichen und finanziellen
Rahmenbedingungen« unterstütze, »um die Voraussetzungen für eine
optimale Nutzung eines offenen Zugangs \[zu wissenschaftlichen
Publikationen\] zu ermöglichen.« Was hier als »Bestärkung« und
»Weiterentwicklung« ganz zwanglos daherkommt, stellte sich freilich
schon auf dem halben Weg vom Jahr 2003 ins aktuelle Jahr 2009 als
durchaus zwanghaft heraus. Denn als es um die konkrete Applikation
dieser Ziele ging, las man im Jahre 2006 in einem Papier der
Deutschen Forschungsgemeinschaft (DFG), dem wichtigsten und
finanziell potentesten Akteur der »Allianz der
Wissenschaftsorganisationen«,[^1] plötzlich nicht nur davon, daß die
Bereitschaft zum elektronischen Publizieren gemäß »Open Access«
durch »externe Anreize« gestärkt werden sollte, man las im selben
Papier nur einen Satz später das kaum kaschierte Bedauern darüber,
daß die »Hochschulleitungen, die am ehesten einen gewissen
(institutionellen) Druck ausüben könnten, \[\...\] bislang
allerdings eher zurückhaltend \[sind\] bei der aktiven Propagierung
elektronischer Publikationen.«

Um der Sache folglich auf die Sprünge zu helfen und die nötigen
»externen Anreize« in Form »eines gewissen (institutionellen)
Drucks« zu setzen, stellten die Allianzorganisationen kurzerhand
ihre Förderpolitik auf »Open Access« um. Das bedeutet konkret, daß
diejenigen Forscher, die seither etwa bei der DFG einen Antrag auf
Forschungsförderung stellen, mit der »Erwartungshaltung« der DFG
konfrontiert werden, ihre geförderten Forschungsergebnisse per »Open
Access« zu veröffentlichen.  So heißt es in den
DFG-Verwendungsrichtlinien für die Exzellenzeinrichtungen, mit deren
Hilfe man bundesweit die berühmten wissenschaftlichen »Leuchttürme«
in die graue Nacht des wissenschaftlichen Durchschnitts stellt: »Die
DFG erwartet \[sic\], dass die mit Mitteln der Exzellenzinitiative
finanzierten Forschungsergebnisse zeitnah publiziert und dabei
möglichst auch digital veröffentlicht und für den entgeltfreien
Zugriff im Internet (Open Access) verfügbar gemacht werden. Die
entsprechenden Beiträge sollten dazu entweder zusätzlich zur
Verlagspublikation in disziplinspezifische oder institutionelle
elektronische Archive (Repositorien) eingestellt oder direkt in
referierten bzw. renommierten Open Access Zeitschriften \[sic\]
publiziert werden.« Was diese Formulierung für einen antragswilligen
Forscher bedeutet, liegt auf der Hand: Er formuliert den Antrag so,
daß die »Erwartung« der DFG bedient wird, ohne lange darüber
nachzudenken, ob die DFG eine solche Erwartung, die der
Wissenschaftsfreiheit hohn spricht, überhaupt haben darf. Wobei die
DFG, die ja als Selbstverwaltungsverein von Wissenschaft auftritt,
sich jederzeit darauf berufen kann, daß das, was sie »erwartet«, der
selbstverwaltete Gemeinschaftswille der deutschen Forscher
ist. Damit sind dann der Wille zu »Open Access« und der damit
verbundene Abbauwille in Sachen Wissenschaftsfreiheit aufs schönste
dadurch legitimiert, daß die Wissenschaftler in ihrer Gesamtheit es
offenbar genau so haben wollen. Wer als Wissenschaftler dagegen
Einwände erhebt und etwas anderes will, der kann diese seine
Einwände und seinen eigenen Willen nur noch als ohnmächtigen
Eigenwillen gegen einen übermächtigen Kollektivwillen stellen, um
hinfort die undankbare Rolle eines wissenschaftlichen Michael
Kohlhaas zu spielen. Kurz und gut: Die Wissenschaftler werden von
den Allianzorganisationen mit einer Förderpolitik konfrontiert, die
ihnen die freie Wahl des Publikationsweges nimmt.

<img
src="https://upload.wikimedia.org/wikipedia/commons/7/7c/Universit%C3%A4t_Bielefeld_Luftaufnahme_Juni_2022.jpg"
alt="Drawing" style="width: 700px;"/>[Universität Bielefeld. Ein
wesentlicher Akteur der »Open-Access«-Bewegung. Quelle: LukeLER, CC
BY-SA 4.0, via Wikimedia Commons.]

Nun kann man natürlich meinen, »Anreize« seien bloß »Anreize«,
»Erwartungen« bloß »Erwartungen«, weshalb eine direkte Nötigung der
Wissenschaftler aus alldem nicht abgeleitet werden könne; und
überhaupt: es gehe ja nur um Zeitschriftenaufsätze, die im Rahmen
drittmittelfinanzierter Forschungsprojekte entstanden seien; die
»normale« Forschung und die monographienträchtigen Fächer gehe das
alles folglich rein gar nichts an. Ein solches Meinen verrechnet
sich indessen schneller, als ihm lieb sein kann, denn es verkennt
nicht nur die Logik universitärer Evaluationsstrukturen, sondern muß
auch die Augen vor den bereits geschaffenen förderungspolitischen
Fakten fest verschließen.

Zunächst zu den universitären Evaluationsstrukturen. In
Universitäten, in denen praktisch jede ausgeschriebene Professur an
die Bedingung geknüpft ist, daß der erfolgreiche Kandidat für
reichlich Drittmittel zu sorgen habe, in Universitäten, in denen
praktisch jede Professur einen Beitrag zu universitätsinternen und
womöglich auch nationalen Forschungsverbünden zu leisten hat, in
Universitäten, in denen die interne Zuteilung von
Forschungszuschüssen und die Höhe der professoralen Gehälter von der
Evaluation des Publikationsaufkommens abhängig gemacht wird --- in
solchen Universitäten sind die Professoren längst keine
individuellen Wissenschaftler mehr, sondern Forschungsarbeiter,
deren Fort- und Einkommen davon abhängt, wie gut sie sich in ein
Forschungssystem, das ihnen die Forschungsziele vorgibt,
einfügen. Dieses System ist in den Naturwissenschaften als
arbeitsteiliges System perfektioniert, aber nicht auf die
Naturwissenschaften beschränkt. Vielmehr sehen wir es derzeit
überall dort auftauchen, wo die »Exzellenzinitiative« für einen
warmen Regen von Drittmitteln sorgt und unterschiedslos erwartet,
daß die so beregneten Fächer sich diesem System fügen. Und selbst
dort, wo man ohne Drittmittel auskommen muß, beeilt man sich, die
internen Strukturen mit diesem neuen Modell kompatibel zu machen, um
bei der nächsten exzellenten Antragsrunde oder dem allfälligen
Universitätsranking den gerade herrschenden Kriterienmix bedienen zu
können. Was dabei vom ganz Großen bis zum ganz Kleinen entsteht, ist
ein nationales und letztlich weltweites Forschungssystem, dem sich
kein Wissenschaftler mehr entziehen kann und das noch in der
scheinbar abseitigsten Provinzuniversität und dem scheinbar
überflüssigsten Orchideenfach dafür sorgt, daß die dort überlebenden
Wissenschaftler systemobservant agieren. Wer daher meint, er könne
in diesem System ungeschoren seine ganz »normale« Forschung
betreiben und seine Monographien auf Dauer an »Open Access« vorbei
publizieren, der irrt in der Tat, und zwar gewaltig. Er hängt, auch
wenn er es noch nicht gemerkt haben sollte, längst am Tropf des
»Open-Access«-Systems.

Der Irrtum zeigt sich in seinem ganzen Ausmaß, wenn man einen Blick
auf die forschungs- und förderungspolitischen Fakten wirft. So
»erwartet« die DFG, wie wir gesehen haben, ja nicht nur
unterschiedslos von allen geförderten Exzellenzeinrichtungen, daß
diese ihre Forschungsergebnisse digital und per »Open Access«
publizieren, die DFG erwartet genau dasselbe von den von ihr
geförderten Graduiertenkollegs und will also im Grunde vom Doktorand
bis arrivierten Wissenschaftler publikationspolitisch nur das eine:
digitale Veröffentlichungen per »Open Access«. Daß diese Erwartungen
sich nicht nur auf Publikationen beziehen, die im Rahmen der
drittmittelfinanzierten Forschung entstanden sind, verrät die am
25. März 2009 veröffentlichte »Gemeinsame Erklärung der
Wissenschaftsorganisationen«, in der es heißt: »Die Allianz der
Wissenschaftsorganisationen fordert eine für den Leser entgeltfreie
Publikation (Open Access) ausschließlich von Forschungsergebnissen,
die durch den Einsatz öffentlicher Mittel und damit zum Nutzen der
Forschung und Gesellschaft insgesamt erarbeitet wurden.« Damit ist
die forschungs- und publikationspolitische Katze aus dem Sack:Weil
alle Hochschulforschung in Deutschland »durch den Einsatz
öffentlicher Mittel« zustande kommt, ist sie der Öffentlichkeit
dadurch tributpflichtig, daß sie ihre Forschungsresultate per »Open
Access« veröffentlicht und also kostenlos ins Internet stellt. Falls
das noch nicht deutlich genug sein sollte, sei es hiermit noch
deutlicher gemacht: Die Logik, der man hier folgt, ist eine Logik
der wissenschaftlichen Unterschiedslosigkeit, die Wissenschaft als
ein steuerfinanziertes System denkt, das dem Steuerzahler gehört und
diesem medial zur Verfügung zu stehen hat --- über alle Fächer
hinweg, in allen Publikationsformen.

Damit betreibt man zuletzt die Annullierung der
Wissenschaftsfreiheit, die als ein Grundrecht in unserer Verfassung
implementiert ist und im Urheberrecht ihren unmittelbar
rechtspraktischen Niederschlag findet.  Wie weit man auf diesem
Annullierungspfad bereits getrampelt ist, zeigen wiederum die
»Verwendungsrichtlinien Exzellenzeinrichtungen« der DFG, in denen es
heißt: »An Exzellenzeinrichtungen beteiligte Wissenschaftler sollten
sich in Verlagsverträgen möglichst ein nicht ausschließliches
Verwertungsrecht zur elektronischen Publikation ihrer
Forschungsergebnisse zwecks entgeltfreier Nutzung fest und dauerhaft
vorbehalten.« Hier wird in Form des »Sollens« genau das vorgetragen,
was im Rahmen der Wissenschaftsfreiheit gar nicht vortragbar ist,
weil das »nicht ausschließliche Verwertungsrecht« dem
Wissenschaftler die Kontrolle über seine Veröffentlichungen
entzieht: Texte, auf die der Urheber keine ausschließlichen Rechte
mehr hat, sind von vorneherein und prinzipiell Texte, die in ein
Textkollektiv --- wir erkennen hier unschwer die von der Allianz
beschworene »Gesellschaft« als der Herrin der Forschung wieder ---
so eingebracht werden, daß das Kollektiv der Textverbraucher die
maßgebliche Instanz ist und nicht der individuelle
Textproduzent. Wird nun aber gar versucht, dieses noch ein wenig
weiche Sollen in eine harte juristische Form zu überführen, wird der
Zwang vollends sichtbar, auf den hin das alles angelegt ist. Dazu
muß man sich lediglich die Antwort anschauen, die die DFG im Sommer
2009 auf eine Anfrage der Bundesregierung zur Reform des
Urheberrechts gab: »Als zwingende \[sic\] Regelung im
Urhebervertragsrecht sollte wissenschaftlichen Autoren nach einer
angemessenen Embargofrist ein unabdingbares \[sic\] und
formatgleiches Zweitveröffentlichungsrecht für ihre Aufsätze und
unselbständig erschienenen Werke eingeräumt werden.  Dieses
Zweitveröffentlichungsrecht, das für den Wissenschaftler keine
Pflicht bedeutet, ist notwendig, um ihn in seiner
Verhandlungsposition gegenüber großen wissenschaftlichen Verlagen zu
stärken. Der Wissenschaftler erhält durch das
Zweitveröffentlichungsrecht die Möglichkeit, selbst über den Grad
der Sichtbarkeit seiner Forschungsergebnisse zu entscheiden. Er übt
dabei in besonderer Weise das Grundrecht der Wissenschaftsfreiheit
aus.«

<img
src="https://upload.wikimedia.org/wikipedia/commons/9/9a/Grab_Reinhart_Koselleck.jpg"
alt="Drawing" style="width: 450px;"/>[Reinhart Kosellecks Grab in
Bielefeld. Quelle: Harvey Kneeslapper, CC BY-SA 4.0, via Wikimedia
Commons.]

Dieser Text spaltet das bisherige Urheberrecht, das keine
Unterschiede zwischen belletristischen und wissenschaftlichen
Autoren kannte, um zwei Klassen von Autoren zu konstruieren: solche,
die kein Zweitveröffentlichungsrecht wahrnehmen können (alle
nicht-wissenschaftlichen Autoren), und solche, die es wahrnehmen
können (alle wissenschaftlichen Autoren). Dieses, wie es auf den
ersten Blick scheint, Mehr an Recht für wissenschaftliche Autoren,
ist aber faktisch ein Weniger: Ein mit einem unabdingbaren
Zweitveröffentlichungsrecht ausgestatteter Autor ist für einen
Verlag kein echter Vertragspartner mehr, weil er dank seines
unabdingbaren Zweitveröffentlichungsrechts dem Verlag den Text nach
einer gewissen Frist wieder entziehen und dem Verlag damit die
Chance nehmen kann, die Publikationskosten einzuspielen. Damit läuft
dieses Recht auf eine Zerstörung der Partnerschaft von Wissenschaft
und Verlagswesen hinaus, um den Strom der wissenschaftlichen
Publikationen in ein neues Bett zu lenken, das auf den Namen »Open
Access« hört. Dort findet sich in Zukunft wieder, wer als
Wissenschaftler veröffentlicht, und dort findet er sich in einem
»Docuverse« wieder, in dem er sich das aus der Computerei übliche
»Patchen« seiner Texte gefallen lassen muß, in jedem Fall aber
dankbar zu sein hat, daß er nun, als Autor im Internet, ungeheuer an
»Sichtbarkeit« gewonnen hat, wie die »Allianz« nicht müde wird zu
behaupten.

Wie aberwitzig das alles ist, wird spätestens dann klar, wenn man
konkret zu werden versucht. Dann türmen sich die Fragwürdigkeiten in
den Himmel: Wie wäre etwa mit dem Werk Hans Blumenbergs zu
verfahren, das zweifellos nur zustande kam, weil er als
Hochschullehrer aus öffentlichen Mitteln bezahlt wurde? Muß das ab
sofort von der Universitätsbibliothek Münster per »Open Access« zur
Verfügung gestellt werden? Und das Werk Hans-Ulrich Wehlers ebenso,
nur diesmal von der Universitätsbibliothek Bielefeld? Wer hätte es
gewagt, Jan Assmann zu sagen, daß seine Beziehungen zum Beck-Verlag
ein baldiges Ende zu nehmen haben, sein Werk aber auf einem
universitären Volltextserver digital wiedererstehen werde? Oder
müssen wir in Zukunft damit leben, daß es jeden dieser und viele
andere Wissenschaftler zweimal gab und gibt, einmal als einen
wochentags aus öffentlichen Mitteln bezahlten Forscher, und einmal
als einen am Wochenende denkenden Privatier, der das privat Gedachte
in renommierten Verlagen veröffentlicht, das öffentlich Gedachte
aber auf Volltextservern, wo es zusammen mit den unveröffentlichten
Dissertationen gescheiterter Denker ein Datengrab findet? Und wenn
wir in Zukunft mit solchen wissenschaftlichen Doppelexistenzen leben
müßten, wer dürfte dann entscheiden, was als Öffentlichgedachtes auf
die »Open-Access«-Server gehört und was als Privatgedachtes an
Verlage gehen darf? Der Wissenschaftler selbst? Ein
Universitätsausschuß? Ein DFG-Gremium?

Um diesem Aberwitz ein Ende zu machen, braucht es wenig. Man muß
dazu nur auf die institutionelle Position hinweisen, von der aus die
»Allianz der Wissenschaftsorganisationen« spricht. Es handelt sich
um die Position von Einrichtungen, die zu einhundert Prozent vom
Staat über Steuermittel finanzierte werden, so daß man erwarten
sollte, daß sie als vollständig staatsfinanzierte Organisationen
nicht nur eine abstrakt rechtliche, sondern auch eine konkret
grundrechtskonforme Position vertreten; und das heißt in dem
Kontext, um den es hier geht: daß sie die Wissenschaftsfreiheit zur
obersten Maxime ihres Handelns machen. Tun sie es nicht --- und sie
tun es in der Tat nicht ---, widersprechen sie ihrer eigenen Raison
d'être, und darüber ist dann nicht mehr in weiteren schönen Worten
zu diskutieren, sondern hier sind dann bloß noch konsequente Taten
zu fordern. Dazu gehört, daß die Politik in Form der zuständigen
Ministerien in den Allianzorganisationen nach dem Rechten schaut und
eine mit dem Grundgesetz wieder zu vereinbarende Forschungsförderung
durchsetzt.

<img
src="https://upload.wikimedia.org/wikipedia/commons/a/aa/Bloomers.png"
alt="Drawing" style="width: 600px;"/>[Turner an der
Sprossenwand. Quelle: http://lcweb2.loc.gov/cgi-bin/query/i, Public
domain, via Wikimedia Commons.]

## An der Sprossenwand

Fragt man sich nach alldem, wie es geschehen konnte, daß die
Forschungsverwalter nicht nur nichts dabei finden, sich eines
Orwellschen Neusprech zu bedienen, bei dem ein Euphemismus auf den
anderen getürmt wird, sondern auch mittels solcher Euphemismen eine
Politik verfolgen, die das selbstbestimmte Individuum zu Grabe
trägt, so ist die Antwort überraschend einfach: Die
Forschungsverwaltung ist primär Verwaltung und nicht Forschung, auch
wenn diejenigen, die in der Forschungsverwaltung Karriere machten
und machen, dies auf der Basis eines Universitätsstudiums tun. Aber
diese Basis ist eben nur die Basis, das Sprungbrett, von dem aus man
in administrative Höhen zu springen versucht, um dort, wie es so
schön heißt, als »Entscheider« Fakten schaffen und Zukunft gestalten
zu können. Daß man in diesen Höhen machtbewußte Menschen findet,
versteht sich von selbst, und gegen diese Selbstverständlichkeit
anzuschreiben, wäre wahrscheinlich eine Donquichotterie. Was sich
dagegen nicht von selbst versteht, ist die spezifische Machtlogik,
die sich im System der »Open-Access«-konformen Forschungsförderung
ausprägt und zu Verhältnissen führt, wie wir sie derzeit haben.

Um dieser Machtlogik auf die Spur zu kommen, lohnt es sich, einen
Blick auf das Personal werfen, das in Sachen »Open Access«
agiert. Maßgeblich ist hierbei der DFG-Unterausschuß für
elektronisches Publizieren, der das Expertengremium darstellt, in
dem die DFG die Weichen für die Zukunft des wissenschaftlichen
Veröffentlichens stellen läßt. Von den neun Mitgliedern dieses
Ausschusses sind vier Bibliothekare (darunter drei
Bibliotheksdirektoren) und fünf Universitätsprofessoren, wobei nicht
nur die vier Bibliothekare sich durch »Open-Access«-affines
Verhalten einen Namen gemacht haben, sondern auch die Mehrheit der
Professoren sich durch eine starke Neigung zu Daten und Digitalem
auszeichnet: Es gibt da einen experimentellen Psychologen, einen
Informatiker, einen Germanisten, der sich programmatisch den
»Digital Humanities« verschrieben hat, und eine den Unterausschuß
leitende Historikerin, die »Geschichtswissenschaft und Neue Medien«
nicht nur als eines ihrer Forschungsfelder nennt, sondern die sich
auch gleich noch durch den Aufbau einer elektronischen
Fachzeitschrift für die Geschichtswissenschaft hervorgetan hat,
einer elektronischen Fachzeitschrift übrigens, die selbst wiederum
von der DFG gefördert wird. Nur der in dem Gremium sitzende Chemiker
hat keine von außen erkennbaren Digitalisierungsambitionen. Wie es
scheint, wurde dieses Gremium zwar nach einem vagen
Wissenschaftsproporz besetzt, aber es ist offensichtlich, daß man es
nicht für nötig hielt, die Vielfalt der Wissenschaften und ihrer
Publikationskulturen abzubilden oder den Rat von Altphilologen und
Althistorikern und den von Buch-, Bibliotheks- und
Medienwissenschaftlern personell zu berücksichtigen. Damit schneidet
sich der Ausschuß von all dem ab, was man über die Mediengeschichte
wissen sollte und müßte, wenn man erfahrungsgesättigte Urteile über
die zukünftige Entwicklung der Medien fällen und auf der Basis
fundierter Urteile Entscheidungen treffen will.

Dies wäre um so wichtiger, als die gesamte Digitalisierungspolitik
ja von einer Eile getrieben ist, deren Gründe niemand zu sagen
weiß. Es sieht so aus, als genüge es, das Phantasma einer
Totaldigitalisierung des »Weltwissens« nur bunt genug auszumalen und
Google als Beschleunigungsvorbild zu propagieren, um überall den
Reflex eines hastigen Nacheiferns auszulösen, bei dem man nun zwar
nicht über Leichen, aber doch immerhin über Grundrechte zu gehen
bereit ist. Gegen solche Phantasmen helfen in der Tat historische
Erinnerungen wie die, daß man in Diogenes Laertios’ (um 200 n. Chr.)
*Leben und Meinungen berühmter Philosophen* heute noch nachlesen
kann, welch ungeheure wissenschaftlich-literarische Produktivität
die antiken Autoren auf der medientechnischen Basis von Papyrus und
Rohrfeder entwickelt haben. Und es helfen begriffliche
Präzisierungen wie die, daß gespeicherte Daten so wenig wie
gedruckte Texte »Wissen« sind, sondern nichts weiter als -- Daten,
über deren Sinn und Zweck nicht durch Akkumulation immer weiterer
wissenschaftlich-technischer Gadgets entschieden wird, sondern nur
durch die sehr individuellen Köpfe denkender Menschen.

<img
src="https://upload.wikimedia.org/wikipedia/commons/f/fc/Bundesarchiv_Bild_102-12352%2C_%C3%84ltestes_Turnpferd.jpg"
alt="Drawing" style="width: 600px;"/>[Das älteste Turnpferd. Quelle:
Bundesarchiv, Bild 102-12352 / CC-BY-SA 3.0, CC BY-SA 3.0 DE, Public
domain, via Wikimedia Commons.]

Von alldem läßt das Personal des DFG-Unterausschusses für
elektronisches Publizieren nichts erkennen. Was es statt dessen
erkennen läßt, ist der unbedingte Wille zum Digitalen, so daß unser
Ausschuß also insgesamt gar nicht als neutral-beratende
Reflexionsinstanz, sondern als Speerspitze des Digitalen amtiert und
entsprechend gefärbte Empfehlungen in den DFG-Gremien nach oben
reicht, wo sie dann, im Vertrauen auf die Sachkompetenz des
Unterausschusses, approbiert werden. Diese Empfehlungen bedienen
sich in der Regel dreier Standardargumente, die »Open Access«
legitimieren sollen.

Erstens komme das wissenschaftliche Publizieren via »Open Access«
den Staat billiger als das bisherige konventionelle Publizieren über
Verlage, denn im bisherigen Modell zahle der Staat für jede
Publikation dreifach (er bezahlt die Wissenschaftler, er bezahlt das
Forschungsprojekt, und er bezahlt die Bibliotheken, die die von den
Wissenschaftlern veröffentlichten Texte von kommerziellen Verlagen
zurückkaufen müßten), im »Open-Access«-Modell aber nur einfach (er
bezahlt die Publikationsgebühren, die bei »Open Access« anfallen).
Zweitens würde »Open Access« die Wissenschaft gleichsam beflügeln,
denn wenn die Forschungsergebnisse weltweit im Netz bereitstünden,
senke das die Recherchekosten, mache Doppelforschungen überflüssig
und verbessere insgesamt die wissenschaftliche Kommunikation, so daß
schneller bessere Resultate zu erwarten seien. Und drittens
schließlich erhöhe »Open Access« nicht nur die gesellschaftliche
»Sichtbarkeit« von Wissenschaft, sondern ermögliche mehr Menschen
als jemals zuvor den Zugang zu wissenschaftlichen
Veröffentlichungen, was unter demokratietheoretischen,
entwicklungspolitischen und moralischen Gesichtspunkten hochgradig
wünschenswert sei.

Keines dieser Argumente hält freilich einer genaueren Prüfung
stand. Für die Kosten des wissenschaftlichen Publizierens ist es
nicht ausschlaggebend, wie oft innerhalb eines Publikationssystems
zu bezahlen ist, sondern wie hoch die Summe der anfallenden
Transaktionskosten ausfällt. Nun liegen die medienunabhängigen
Kosten für eine wissenschaftliche Veröffentlichung bei etwa 1800
Euro pro Publikation, so daß man auf dieser Basis sehr leicht
ausrechnen kann, was eine vollständige Umstellung der
wissenschaftlichen Veröffentlichungen auf »Open Access« für den
deutschen Steuerzahler bedeuten würde. Man muß dazu lediglich
wissen, daß bei »Open Access« die Publikationskosten zu einhundert
Prozent von den Produzenten bzw. deren Hochschulen und also
letztlich vom Steuerzahler zu tragen sind und sich nicht, wie im
jetzigen Publikationssystem, auf viele interessierte Abnehmer in
Gesellschaft, Wissenschaft und Industrie im In- und Ausland
verteilen.  Nun muß man nur noch die Anzahl der Wissenschaftler in
Deutschland kennen (175000 Personen) und diese mit der
voraussichtlichen Anzahl der von ihnen geschriebenen Publikationen
und den Kosten von 1800 Euro pro Publikation multiplizieren, um dies
herauszufinden: Würde jeder deutsche Wissenschaftler pro Jahr drei
Texte via »Open Access« veröffentlichen, müßte der Steuerzahler
dafür 945 Mio. Euro aufwenden, rund 160 Mio. Euro mehr, als er
bisher für die wissenschaftlichen Bibliotheken ausgibt, die er mit
785,5 Mio. Euro finanziert. Anders gesagt: Der Steuerzahler muß sich
überlegen, ob er für 525 000 »Open-Access«-Veröffentlichungen seiner
Wissenschaftler 945 Mio. Euro zu investieren bereit ist -- wobei in
diesem Betrag die Infrastrukturkosten, die das Netz verursacht, noch
gar nicht berücksichtigt sind --, um sich danach darüber zu freuen,
daß er diese Publikationen »kostenlos« im Netz abrufen kann, oder ob
er nicht doch besser 785,5 Mio. Euro in seine wissenschaftlichen
Bibliotheken steckt, die dafür 580 000 Zeitschriftenabonnements
tätigen, 3,4 Mio. Bücher kaufen und 2,3 Mio. Kauflizenzen von
digitalen Medien erwerben -- und darüber hinaus das geschulte
Personal bereitstellen, um allen Wissenshungrigen auf die Sprünge zu
helfen.

<img
src="https://upload.wikimedia.org/wikipedia/commons/a/ae/JMRC_Best_Warrior_Competition_150317-A-SG416-004.jpg"
alt="Drawing" style="width: 450px;"/>[Klimmzug. Quelle:
Pfc. Shardesia Washington, Public domain, via Wikimedia Commons.]

Man versteht nun, warum Matthias Kleiner, der Präsident der DFG, in
einem im September veröffentlichten Interview mit der Zeitschrift
*Forschung & Lehre* betonte, die DFG mache sich nicht für »Open Access«
stark, »weil es weniger kostet, sondern weil es Forschungsergebnisse und
deren Autoren weltweit noch sichtbarer macht.« Denn wenn man mit dem
Kostenargument öffentlich nicht mehr punkten kann, dann versucht man es
wenigstens mit dem Funktionsargument und der Moral. Aber auch hier ist
die Sache prekär: Wer »Open Access« befürwortet, weil es eine
funktionalere Wissenschaft ermögliche (schnellere und bessere Resultate
und die dann auch noch »sichtbarer«), der hat sich von einem Begriff von
Wissenschaft verabschiedet, dem es um die Reflexion von Inhalten deshalb
zu tun war, weil nicht die Inhalte je für sich zur Erkenntnis von
Wahrheit führen, sondern einzig die geduldige begriffliche Reflexion
ebendieser Inhalte. Statt dessen haben wir nun eine Wissenschaft als
Umschlagplatz von sichtbaren »Resultaten«, die im elektronischen Medium
weltweit distribuiert werden können und, als »Resultate«, eine sofortige
Einsatzfähigkeit in beliebigen Kontexten suggerieren: hier wird mit
einem schnellen Patent der Wohlstand verbessert und dort mit der
richtigen »Information« die Demokratie befördert.

In Wahrheit ist damit die Frage nach der Wahrheit erfolgreich
abgeschafft und durch eine systemische Richtigkeit ersetzt, über die
ebenjene Akteure entscheiden, die für die Selbstreproduktion des
Wissenschaftssystems sorgen. Das sind, wir wissen es, nicht die
Wissenschaftler, sondern all die Namenlosen, die im Verzicht auf
eigene schriftstellerisch-wissenschaftliche Produktivität eine
unauffällige Laufbahnkarriere einschlugen, die sich von außen
betrachtet als Dienst und Service an der Sache der Wissenschaft
darstellt. Ihr historisches Modell ist der Bibliothekar und ihr
Namenspatron Friedrich Adolf Ebert, dessen letaler Sturz von der
Leiter der Dresdener Bibliothek das Programm bezeichnet, das seither
exekutiert wird: mit ganzem Einsatz Sprosse für Sprosse nach oben,
um dort --- von oben als dem eigentlichen Innen --- das System zu
regulieren. Nach zweihundert Jahren an der Sprossenwand erleben wir
nun, wie die Diener und Serviceleister dabei sind, zu den
eigentlichen Herren des Wissenschaftssystems zu mutieren.  Der
Vollzug dieser Mutation erfordert zwingend, daß der produktive
wissenschaftliche Impuls, der ohne das Selbstbestimmungsrecht des
Individuums nicht zu haben ist, zu einer abhängigen Variablen der
wissenschaftlichen Servicesysteme wird, und es ist daher mehr als
konsequent, daß die Allianzorganisationen nicht nur als Geldgeber
wissenschaftlicher Forschungsprojekte auftreten, sondern unter dem
Namen »Open Access« dazu übergehen, den über diese
Forschungsprojekte generierten wissenschaftlichen »Output« in ein
Publikationssystem zu nötigen, in dem der wissenschaftliche Autor
auf seine Wissenschaftsfreiheit und also seinen Status als freier
Wissenschaftler verzichten muß.

Es ist daher hohe Zeit, »Open Access« als das erkennen, was es ist: der
Kokon einer staatsmonopolistischen Auftragsforschung, aus der keine
Wahrheit mehr schlüpfen soll, sondern ein digitales »Weltwissen«, das
beliebige Inhalte an beliebigen Orten zu beliebigen Zeiten bereitstellt
und diese globale Beliebigkeit als wissenschaftlichen Globalservice
vermarktet.

<img
src="https://upload.wikimedia.org/wikipedia/commons/e/e9/Charlotte_Dujardin_2012_Olympic_Dressage-1.JPG"
alt="Drawing" style="width: 450px;"/>[Dressurreiten. Quelle:
Nordlicht8, CC BY-SA 3.0, via Wikimedia Commons.]


### Anmerkung

[^1]: Die »Allianz« besteht aus der Deutschen Forschungsgemeinschaft,
    der Fraunhofer Gesellschaft, der Max-Planck-Gesellschaft, der
    Helmholtz-Gemeinschaft Deutscher Forschungszentren, der
    Hochschulrektorenkonferenz, der Leibniz-Gemeinschaft und dem
    Wissenschaftsrat.


